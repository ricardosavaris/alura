{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOuHAkfa91SfiL6cttjU0lJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricardosavaris/alura/blob/main/Foxo1ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "067956d7"
      },
      "source": [
        "# --- Section 1: Setup and Data Loading ---\n",
        "\n",
        "# Import necessary libraries for data analysis, visualization, and statistical modeling.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import pingouin as pg\n",
        "from scipy.stats import normaltest, levene, kruskal, shapiro\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from google.colab import drive # Keep if accessing from Drive\n",
        "from google.colab import auth # Keep if accessing from Drive\n",
        "import gspread # Keep if accessing from Drive\n",
        "from scipy.stats import f_oneway, kruskal # Import f_oneway\n",
        "import statsmodels.stats.oneway as oneway\n",
        "\n",
        "# Define the path to the uploaded Excel file\n",
        "file_path = 'FOXO1_raw_data.xlsx' # Assuming the file is in the default /content/ directory\n",
        "\n",
        "# Read the Excel file into a pandas DataFrame\n",
        "try:\n",
        "    df = pd.read_excel(file_path, engine='openpyxl')\n",
        "    print(\"DataFrame loaded successfully from local file:\")\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e27cc7a2"
      },
      "source": [
        "**Reasoning**:\n",
        "Arrange the remaining code cells in a logical order that reflects the steps of the analysis presented in the manuscript (e.g., Data Loading -> Data Preparation -> Descriptive Statistics -> Group Comparisons -> Regression Analysis 1 -> Regression Analysis 2 -> Table Generation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2013ec0e"
      },
      "source": [
        "# Define the variables to analyze\n",
        "variables_to_analyze = ['Age', 'BMI', 'End Tickness', 'Serum E2 (pg/ml)', 'Serum P4 (ng/ml)', 'PGR QPath', 'FOXO1 Qpath']\n",
        "\n",
        "# Define the groups\n",
        "groups = df['Group'].unique()\n",
        "\n",
        "# Dictionary to store the results\n",
        "summary_data = {}\n",
        "\n",
        "for group in groups:\n",
        "    group_df = df[df['Group'] == group].copy()\n",
        "    summary_data[group] = {}\n",
        "\n",
        "    for variable in variables_to_analyze:\n",
        "        if variable in group_df.columns:\n",
        "            data = group_df[variable].dropna()\n",
        "\n",
        "            if not data.empty:\n",
        "                # Calculate descriptive statistics\n",
        "                mean = data.mean()\n",
        "                std_dev = data.std()\n",
        "                median = data.median()\n",
        "                data_range = data.max() - data.min()\n",
        "                n = len(data)\n",
        "\n",
        "                # Perform normality test\n",
        "                if n >= 8: # D'Agostino's test requires at least 8 data points\n",
        "                    k2, p_value = normaltest(data)\n",
        "                    normality_passed = 'Yes' if p_value > 0.05 else 'No' # Assuming alpha = 0.05\n",
        "                else:\n",
        "                    normality_passed = 'Not enough data (n < 8)'\n",
        "\n",
        "                summary_data[group][variable] = {\n",
        "                    'n': n,\n",
        "                    'Mean': mean,\n",
        "                    'Std Dev': std_dev,\n",
        "                    'Median': median,\n",
        "                    'Range': data_range,\n",
        "                    'Normal Distribution (p>0.05)': normality_passed\n",
        "                }\n",
        "            else:\n",
        "                summary_data[group][variable] = 'No data available'\n",
        "        else:\n",
        "            summary_data[group][variable] = 'Variable not found'\n",
        "\n",
        "\n",
        "# Prepare data for a consolidated table\n",
        "all_summary_data = []\n",
        "for group, variables_data in summary_data.items():\n",
        "    for variable, stats in variables_data.items():\n",
        "        if isinstance(stats, dict):\n",
        "            row = {'Group': group, 'Variable': variable, **stats}\n",
        "            all_summary_data.append(row)\n",
        "        else:\n",
        "             all_summary_data.append({'Group': group, 'Variable': variable, 'Result': stats})\n",
        "\n",
        "\n",
        "# Create a pandas DataFrame for the summary table\n",
        "summary_table = pd.DataFrame(all_summary_data)\n",
        "\n",
        "# Display the summary table\n",
        "print(\"Descriptive Statistics and Normality Test Summary Table:\")\n",
        "display(summary_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ec5b24"
      },
      "source": [
        "## Check for homoscedasticity\n",
        "\n",
        "### Subtask:\n",
        "For variables that are approximately normally distributed in all three groups, perform a test for equal variances (e.g., Levene's test) across the groups.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1722532"
      },
      "source": [
        "**Reasoning**:\n",
        "Perform Levene's test for equal variances for 'Age' and 'Serum E2 (pg/ml)' across the three groups.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e7769af"
      },
      "source": [
        "from scipy.stats import levene\n",
        "\n",
        "# Identify variables that were approximately normally distributed in all groups\n",
        "normally_distributed_vars = ['Age', 'Serum E2 (pg/ml)']\n",
        "\n",
        "# Define the groups\n",
        "groups = df['Group'].unique()\n",
        "\n",
        "# Perform Levene's test for each normally distributed variable\n",
        "for variable in normally_distributed_vars:\n",
        "    group_data = [df[df['Group'] == group][variable].dropna() for group in groups]\n",
        "\n",
        "    # Ensure there are at least two groups with data for the variable\n",
        "    if len(group_data) >= 2:\n",
        "        statistic, p_value = levene(*group_data)\n",
        "        print(f\"Levene's test for {variable}:\")\n",
        "        print(f\"  Statistic: {statistic:.4f}\")\n",
        "        print(f\"  P-value: {p_value:.4f}\")\n",
        "        print(\"-\" * 30)\n",
        "    else:\n",
        "        print(f\"Not enough groups with data for {variable} to perform Levene's test.\")\n",
        "        print(\"-\" * 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fca7141"
      },
      "source": [
        "## Select and perform appropriate test\n",
        "\n",
        "### Subtask:\n",
        "Perform the appropriate statistical test (ANOVA, Welch's ANOVA, or Kruskal-Wallis) for each variable based on normality and homoscedasticity results, comparing the three groups.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ff82270"
      },
      "source": [
        "**Reasoning**:\n",
        "Based on the normality and homoscedasticity results, perform the appropriate statistical tests for each variable. For 'Age', perform one-way ANOVA. For 'Serum E2 (pg/ml)', perform Welch's ANOVA. For the remaining variables, perform Kruskal-Wallis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c387b67"
      },
      "source": [
        "# Define the variables and the appropriate tests\n",
        "variables_to_test = {\n",
        "    'Age': 'ANOVA',\n",
        "    'BMI': 'Kruskal-Wallis',\n",
        "    'End Tickness': 'Kruskal-Wallis',\n",
        "    'Serum E2 (pg/ml)': 'Welch-ANOVA',\n",
        "    'Serum P4 (ng/ml)': 'Kruskal-Wallis',\n",
        "    'PGR QPath': 'Kruskal-Wallis',\n",
        "    'FOXO1 Qpath': 'Kruskal-Wallis'\n",
        "}\n",
        "\n",
        "# Define the groups\n",
        "groups = df['Group'].unique()\n",
        "\n",
        "# Perform the appropriate test for each variable\n",
        "for variable, test_type in variables_to_test.items():\n",
        "    print(f\"Performing {test_type} test for {variable}:\")\n",
        "\n",
        "    # Prepare data for the test, dropping NaN values for the current variable\n",
        "    group_data = [df[df['Group'] == group][variable].dropna() for group in groups]\n",
        "\n",
        "    # Remove empty groups if any\n",
        "    group_data = [data for data in group_data if not data.empty]\n",
        "\n",
        "    if len(group_data) < 2:\n",
        "        print(f\"  Not enough groups with data for {variable} to perform the test.\")\n",
        "    else:\n",
        "        if test_type == 'ANOVA':\n",
        "            if len(group_data) >= 2: # Ensure at least two groups with data\n",
        "                statistic, p_value = f_oneway(*group_data)\n",
        "                print(f\"  ANOVA Statistic: {statistic:.4f}\")\n",
        "                print(f\"  ANOVA P-value: {p_value:.4f}\")\n",
        "            else:\n",
        "                print(f\"  Not enough groups with data for {variable} to perform ANOVA.\")\n",
        "        elif test_type == 'Welch-ANOVA':\n",
        "             if len(group_data) >= 2: # Ensure at least two groups with data\n",
        "                # Use pingouin.welch_anova\n",
        "                # Create a temporary DataFrame for pingouin\n",
        "                temp_df = pd.DataFrame({variable: pd.concat(group_data), 'Group': df['Group'].loc[pd.concat(group_data).index]})\n",
        "                anova_results = pg.welch_anova(data=temp_df, dv=variable, between='Group')\n",
        "                f_statistic = anova_results['F'].iloc[0]\n",
        "                p_value = anova_results['p-unc'].iloc[0]\n",
        "                print(f\"  Welch's ANOVA Statistic: {f_statistic:.4f}\")\n",
        "                print(f\"  Welch's ANOVA P-value: {p_value:.4f}\")\n",
        "             else:\n",
        "                print(f\"  Not enough groups with data for {variable} to perform Welch's ANOVA.\")\n",
        "        elif test_type == 'Kruskal-Wallis':\n",
        "            if len(group_data) >= 2: # Ensure at least two groups with data\n",
        "                statistic, p_value = kruskal(*group_data)\n",
        "                print(f\"  Kruskal-Wallis Statistic: {statistic:.4f}\")\n",
        "                print(f\"  Kruskal-Wallis P-value: {p_value:.4f}\")\n",
        "            else:\n",
        "                 print(f\"  Not enough groups with data for {variable} to perform Kruskal-Wallis test.\")\n",
        "    print(\"-\" * 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6914c765"
      },
      "source": [
        "from scipy.stats import chi2_contingency, fisher_exact\n",
        "\n",
        "# Create a contingency table of 'Group' and 'HE Dating'\n",
        "contingency_table = pd.crosstab(df['Group'], df['HE Dating'])\n",
        "\n",
        "print(\"Contingency Table (Group vs. HE Dating):\")\n",
        "display(contingency_table)\n",
        "\n",
        "# Perform Chi-squared test\n",
        "# Chi-squared test is generally appropriate for larger sample sizes.\n",
        "# If any cell has an expected frequency less than 5, Fisher's exact test is more suitable.\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"\\nChi-squared Test Results:\")\n",
        "print(f\"  Chi-squared Statistic: {chi2:.4f}\")\n",
        "print(f\"  P-value: {p:.4f}\")\n",
        "print(f\"  Degrees of Freedom: {dof}\")\n",
        "# print(\"  Expected Frequencies Table:\")\n",
        "# display(pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns))\n",
        "\n",
        "# Check if Fisher's exact test is more appropriate (e.g., for small sample sizes)\n",
        "# A common rule of thumb is if any expected cell count is less than 5.\n",
        "# We can check this from the 'expected' array from chi2_contingency.\n",
        "if (expected < 5).any():\n",
        "    print(\"\\nWarning: Some expected cell counts are less than 5. Fisher's exact test may be more appropriate.\")\n",
        "    # For a 3x2 table, Fisher's exact test can be computationally intensive or\n",
        "    # might require a different implementation than scipy.stats.fisher_exact which is for 2x2.\n",
        "    # However, let's perform it if possible or note the need for specialized test for larger tables.\n",
        "    # SciPy's fisher_exact is strictly for 2x2 tables. For larger tables, other libraries or methods are needed.\n",
        "    # We'll stick with the chi-squared output and the warning for now, as it's a common approach for larger tables with some small counts.\n",
        "    pass # We will rely on the chi-squared test results and the warning.\n",
        "else:\n",
        "    print(\"\\nFisher's exact test is not required based on expected cell counts.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Table 1. Characteristics of the studied population"
      ],
      "metadata": {
        "id": "MiaC59qxCSL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the variables and their desired format (mean-SD or median-range)\n",
        "variable_formats = {\n",
        "    'Age': 'mean-SD',\n",
        "    'BMI': 'median-range',\n",
        "    'End Tickness': 'median-range',\n",
        "    'Serum E2 (pg/ml)': 'mean-SD',\n",
        "    'Serum P4 (ng/ml)': 'median-range',\n",
        "    'PGR QPath': 'mean-SD',\n",
        "    'FOXO1 Qpath': 'median-range'\n",
        "}\n",
        "\n",
        "# Define the variables and the appropriate tests (from previous analysis in cell 2c387b67)\n",
        "variables_to_test = {\n",
        "    'Age': 'ANOVA',\n",
        "    'BMI': 'Kruskal-Wallis',\n",
        "    'End Tickness': 'Kruskal-Wallis',\n",
        "    'Serum E2 (pg/ml)': 'Welch-ANOVA',\n",
        "    'Serum P4 (ng/ml)': 'Kruskal-Wallis',\n",
        "    'PGR QPath': 'Kruskal-Wallis',\n",
        "    'FOXO1 Qpath': 'Kruskal-Wallis'\n",
        "}\n",
        "\n",
        "# Dictionary to store the formatted data for the table\n",
        "table_data = {}\n",
        "\n",
        "# Populate the table data with variable names\n",
        "for variable in variable_formats.keys():\n",
        "    table_data[variable] = {}\n",
        "    table_data[variable]['Variables/Characteristics'] = variable\n",
        "\n",
        "# Extract data from the summary_table and format it\n",
        "for index, row in summary_table.iterrows():\n",
        "    group = row['Group']\n",
        "    variable = row['Variable']\n",
        "    mean = row['Mean']\n",
        "    std_dev = row['Std Dev']\n",
        "    median = row['Median']\n",
        "    data_range = row['Range'] # Note: summary_table has Range, not IQR\n",
        "\n",
        "    if variable in variable_formats:\n",
        "        if variable_formats[variable] == 'mean-SD':\n",
        "            formatted_value = f\"{mean:.2f} Â± {std_dev:.2f}\"\n",
        "        elif variable_formats[variable] == 'median-range':\n",
        "            formatted_value = f\"{median:.2f} ({data_range:.2f})\" # Using Range as per summary_table\n",
        "\n",
        "        if group not in table_data[variable]:\n",
        "             table_data[variable][group] = formatted_value\n",
        "        else:\n",
        "             # Handle cases where group name might have extra spaces\n",
        "             table_data[variable][group.strip()] = formatted_value\n",
        "\n",
        "\n",
        "# Add P-value and test used from the results in cell 2c387b67\n",
        "# We need to access the p-values calculated in cell 2c387b67.\n",
        "# Assuming the p-values and test types from cell 2c387b67 are available in memory\n",
        "# We will manually add them based on the output of cell 2c387b67\n",
        "\n",
        "# Manually adding p-values and test names based on the output of cell 2c387b67\n",
        "# Note: This is a temporary solution. In a real scenario, we would store these results\n",
        "# in a more accessible structure in cell 2c387b67.\n",
        "p_values = {\n",
        "    'Age': 0.0870,\n",
        "    'BMI': 0.2770,\n",
        "    'End Tickness': 0.1638,\n",
        "    'Serum E2 (pg/ml)': 0.0000, # Approximate p-value from Welch's ANOVA output\n",
        "    'Serum P4 (ng/ml)': 0.0001,\n",
        "    'PGR QPath': 0.0211,\n",
        "    'FOXO1 Qpath': 0.0001\n",
        "}\n",
        "\n",
        "for variable in variable_formats.keys():\n",
        "    if variable in p_values:\n",
        "        table_data[variable]['P-value'] = f\"{p_values[variable]:.4f}\"\n",
        "        table_data[variable]['test used'] = variables_to_test[variable]\n",
        "\n",
        "\n",
        "# Convert the dictionary to a list of dictionaries and then to a DataFrame\n",
        "table_rows = [data for data in table_data.values()]\n",
        "table1_df = pd.DataFrame(table_rows)\n",
        "\n",
        "# Reorder columns to match the requested format\n",
        "column_order = ['Variables/Characteristics', 'Control', 'IVF  ', 'HRT  ', 'P-value', 'test used']\n",
        "table1_df = table1_df[column_order]\n",
        "\n",
        "# Display the Table 1\n",
        "print(\"Table 1:\")\n",
        "display(table1_df)"
      ],
      "metadata": {
        "id": "wNtsVOUb6AGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the variables to test for normality\n",
        "variables_for_normality_check = ['FOXO1 Qpath', 'PGR QPath', 'Serum E2 (pg/ml)', 'Serum P4 (ng/ml)']\n",
        "\n",
        "print(\"Normality Test Results (D'Agostino's K-squared test) for selected variables:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for variable in variables_for_normality_check:\n",
        "    if variable in df.columns:\n",
        "        # Drop NaN values before testing\n",
        "        data = df[variable].dropna()\n",
        "\n",
        "        if len(data) > 8: # D'Agostino's test requires at least 8 data points\n",
        "            k2, p_value = normaltest(data)\n",
        "            print(f\"{variable}:\")\n",
        "            print(f\"  K2 Statistic: {k2:.4f}\")\n",
        "            print(f\"  P-value: {p_value:.4f}\")\n",
        "            if p_value < 0.05:\n",
        "                print(\"  Result: Not normally distributed (p < 0.05)\")\n",
        "            else:\n",
        "                print(\"  Result: Normally distributed (p >= 0.05)\")\n",
        "        else:\n",
        "            print(f\"{variable}: Not enough data (n < 8) to perform D'Agostino's test.\")\n",
        "    else:\n",
        "        print(f\"Variable not found: {variable}\")\n",
        "    print(\"-\" * 70)"
      ],
      "metadata": {
        "id": "Y3ikVsDUCiCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using different algorithms to achieve normal distribution for the variables : 'FOXO1 Qpath', 'PGR QPath', 'Serum E2 (pg/ml)', 'Serum P4 (ng/ml)'"
      ],
      "metadata": {
        "id": "WxtluEx1EpTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import normaltest, boxcox, rankdata, norm\n",
        "import pandas as pd\n",
        "\n",
        "# Define the variables to transform and test\n",
        "variables_to_transform = ['FOXO1 Qpath', 'PGR QPath', 'Serum E2 (pg/ml)', 'Serum P4 (ng/ml)']\n",
        "\n",
        "# Create a copy of the DataFrame to add transformed columns\n",
        "df_transformed_vars = df.copy()\n",
        "\n",
        "print(\"Exploring transformations for normality:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for variable in variables_to_transform:\n",
        "    original_col = variable\n",
        "\n",
        "    if original_col in df_transformed_vars.columns:\n",
        "        data = df_transformed_vars[original_col].dropna()\n",
        "\n",
        "        if not data.empty and len(data) > 1:\n",
        "            print(f\"Applying transformations to '{original_col}':\")\n",
        "\n",
        "            # --- Log Transformation ---\n",
        "            transformed_col_log = f'{variable}_log'\n",
        "            if (data <= 0).any():\n",
        "                min_positive = data[data > 0].min()\n",
        "                constant = min_positive / 2 if pd.notna(min_positive) else 1e-6\n",
        "                df_transformed_vars[transformed_col_log] = np.log(data + constant)\n",
        "                print(f\"  Log transformation applied with constant {constant:.6f}.\")\n",
        "            else:\n",
        "                df_transformed_vars[transformed_col_log] = np.log(data)\n",
        "                print(f\"  Log transformation applied.\")\n",
        "\n",
        "            # Test Log-transformed variable for normality\n",
        "            data_transformed_log = df_transformed_vars[transformed_col_log].dropna()\n",
        "            if len(data_transformed_log) > 8:\n",
        "                k2_log, p_value_log = normaltest(data_transformed_log)\n",
        "                normality_log = 'Normally distributed (p >= 0.05)' if p_value_log >= 0.05 else 'Not normally distributed (p < 0.05)'\n",
        "                print(f\"  Normality Test (Log): K2={k2_log:.4f}, P={p_value_log:.4f} - {normality_log}\")\n",
        "            else:\n",
        "                 print(f\"  Not enough data (n < 8) for Log Normality Test.\")\n",
        "\n",
        "\n",
        "            # --- Box-Cox Transformation ---\n",
        "            if (data > 0).all():\n",
        "                transformed_col_boxcox = f'{variable}_boxcox'\n",
        "                transformed_data_boxcox, lambda_boxcox = boxcox(data)\n",
        "                df_transformed_vars[transformed_col_boxcox] = transformed_data_boxcox\n",
        "                print(f\"  Box-Cox transformation applied (lambda={lambda_boxcox:.4f}).\")\n",
        "\n",
        "                # Test Box-Cox transformed variable for normality\n",
        "                data_transformed_boxcox = df_transformed_vars[transformed_col_boxcox].dropna()\n",
        "                if len(data_transformed_boxcox) > 8:\n",
        "                    k2_boxcox, p_value_boxcox = normaltest(data_transformed_boxcox)\n",
        "                    normality_boxcox = 'Normally distributed (p >= 0.05)' if p_value_boxcox >= 0.05 else 'Not normally distributed (p < 0.05)'\n",
        "                    print(f\"  Normality Test (Box-Cox): K2={k2_boxcox:.4f}, P={p_value_boxcox:.4f} - {normality_boxcox}\")\n",
        "                else:\n",
        "                    print(f\"  Not enough data (n < 8) for Box-Cox Normality Test.\")\n",
        "            else:\n",
        "                 print(f\"  Box-Cox transformation skipped for '{original_col}' due to non-positive values.\")\n",
        "\n",
        "            # --- Normal Quantile Transformation (NQT) ---\n",
        "            # NQT can be applied to data with zeros or negatives.\n",
        "            if len(data) >= 2: # NQT requires at least 2 data points\n",
        "                transformed_col_nqt = f'{variable}_nqt'\n",
        "                # Calculate ranks\n",
        "                ranks = rankdata(data)\n",
        "                # Calculate quantiles\n",
        "                quantiles = (ranks - 0.5) / len(ranks)\n",
        "                # Apply inverse of normal CDF\n",
        "                transformed_data_nqt = norm.ppf(quantiles)\n",
        "                df_transformed_vars[transformed_col_nqt] = transformed_data_nqt\n",
        "                print(f\"  Normal Quantile Transformation (NQT) applied.\")\n",
        "\n",
        "                # Test NQT transformed variable for normality\n",
        "                data_transformed_nqt = df_transformed_vars[transformed_col_nqt].dropna()\n",
        "                if len(data_transformed_nqt) > 8:\n",
        "                    k2_nqt, p_value_nqt = normaltest(data_transformed_nqt)\n",
        "                    normality_nqt = 'Normally distributed (p >= 0.05)' if p_value_nqt >= 0.05 else 'Not normally distributed (p < 0.05)'\n",
        "                    print(f\"  Normality Test (NQT): K2={k2_nqt:.4f}, P={p_value_nqt:.4f} - {normality_nqt}\")\n",
        "                else:\n",
        "                    print(f\"  Not enough data (n < 8) for NQT Normality Test.\")\n",
        "            else:\n",
        "                 print(f\"  Not enough data ({len(data)} < 2) in '{original_col}' to perform NQT.\")\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(f\"Not enough data ({len(data)} < 2) in '{original_col}' to perform transformations.\")\n",
        "    else:\n",
        "        print(f\"Variable not found: {original_col}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "# Display the head of the DataFrame with new transformed columns\n",
        "print(\"\\nDataFrame head with transformed variables:\")\n",
        "display(df_transformed_vars.head())"
      ],
      "metadata": {
        "id": "SXDUqesKDYE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8579f3f"
      },
      "source": [
        "#df_regression_nqt is available from the previous step (Prepare Data - NQT).\n",
        "\n",
        "if 'df_regression_nqt' not in locals():\n",
        "    print(\"df_regression_nqt not found, creating it from df_transformed_vars...\")\n",
        "    df_regression_nqt = df_transformed_vars[['FOXO1 Qpath_nqt', 'PGR QPath_nqt', 'Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt']].dropna()\n",
        "\n",
        "\n",
        "# Define independent and dependent variables using the NQT transformed data\n",
        "independent_vars_nqt = ['PGR QPath_nqt', 'Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt']\n",
        "dependent_var_nqt = 'FOXO1 Qpath_nqt'\n",
        "\n",
        "# Create scatter plots\n",
        "print(\"Scatter Plots to Check Linearity (NQT Transformed Variables):\")\n",
        "for var in independent_vars_nqt:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(df_regression_nqt[var], df_regression_nqt[dependent_var_nqt])\n",
        "    plt.xlabel(var)\n",
        "    plt.ylabel(dependent_var_nqt)\n",
        "    plt.title(f'Scatter Plot of {dependent_var_nqt} vs. {var}')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nVisual inspection of scatter plots is needed to assess linearity.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe981ad6"
      },
      "source": [
        "# Assuming df_regression_nqt is available from the previous step (Prepare Data - NQT).\n",
        "\n",
        "if 'df_regression_nqt' not in locals():\n",
        "    print(\"df_regression_nqt not found, creating it from df_transformed_vars...\")\n",
        "    df_regression_nqt = df_transformed_vars[['FOXO1 Qpath_nqt', 'PGR QPath_nqt', 'Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt']].dropna()\n",
        "\n",
        "\n",
        "# Define the independent variables (X) and the dependent variable (y) using the NQT transformed data\n",
        "X_nqt = df_regression_nqt[['PGR QPath_nqt', 'Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt']]\n",
        "y_nqt = df_regression_nqt['FOXO1 Qpath_nqt']\n",
        "\n",
        "# Add a constant to the independent variables\n",
        "X_nqt = sm.add_constant(X_nqt)\n",
        "\n",
        "# Fit the linear regression model with NQT transformed variables\n",
        "# We fit the model here to get residuals and predicted values for homoscedasticity check.\n",
        "model_nqt = sm.OLS(y_nqt, X_nqt).fit()\n",
        "\n",
        "# Calculate the predicted values and residuals for the NQT model\n",
        "predicted_values_nqt = model_nqt.predict(X_nqt)\n",
        "residuals_nqt = model_nqt.resid\n",
        "\n",
        "# Create a scatter plot of residuals vs. predicted values for the NQT model\n",
        "print(\"Residuals vs. Predicted Values Plot (NQT Transformed):\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(predicted_values_nqt, residuals_nqt)\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('Predicted Values (NQT Transformed)')\n",
        "plt.ylabel('Residuals (NQT Transformed)')\n",
        "plt.title('Residuals vs. Predicted Values Plot (NQT Transformed)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Perform the Breusch-Pagan test on the NQT model residuals\n",
        "bp_test_nqt = het_breuschpagan(residuals_nqt, X_nqt)\n",
        "\n",
        "# Print the results of the Breusch-Pagan test for NQT model residuals\n",
        "print(\"\\nBreusch-Pagan Test Results (NQT Model):\")\n",
        "print(f\"  Lagrange multiplier statistic: {bp_test_nqt[0]:.4f}\")\n",
        "print(f\"  P-value: {bp_test_nqt[1]:.4f}\")\n",
        "print(f\"  F-statistic: {bp_test_nqt[2]:.4f}\")\n",
        "print(f\"  F-statistic P-value: {bp_test_nqt[3]:.4f}\")\n",
        "\n",
        "print(\"\\nVisual inspection of the plot and the Breusch-Pagan test results are needed to assess homoscedasticity.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual inspection reveals that the data passed the Homoscedasticity test"
      ],
      "metadata": {
        "id": "o6P03cy7JInN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming residuals_nqt is available from the previous step (Homoscedasticity check).\n",
        "if 'residuals_nqt' not in locals():\n",
        "    print(\"residuals_nqt not found, re-running regression to get residuals...\")\n",
        "    if 'df_regression_nqt' not in locals():\n",
        "        print(\"df_regression_nqt not found, creating it from df_transformed_vars...\")\n",
        "        # Assuming df_transformed_vars is available from cell SXDUqesKDYE5:\n",
        "        df_regression_nqt = df_transformed_vars[['FOXO1 Qpath_nqt', 'PGR QPath_nqt', 'Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt']].dropna()\n",
        "\n",
        "    X_nqt = df_regression_nqt[['PGR QPath_nqt', 'Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt']]\n",
        "    y_nqt = df_regression_nqt['FOXO1 Qpath_nqt']\n",
        "    X_nqt = sm.add_constant(X_nqt)\n",
        "    model_nqt = sm.OLS(y_nqt, X_nqt).fit()\n",
        "    residuals_nqt = model_nqt.resid\n",
        "\n",
        "\n",
        "print(\"Checking Normality of Residuals (NQT Transformed Model):\")\n",
        "\n",
        "# Generate a histogram of the residuals for the NQT model\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(residuals_nqt, bins=20, density=True, alpha=0.7)\n",
        "plt.xlabel('Residuals (NQT Transformed)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Residuals (NQT Transformed Model)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Create a Q-Q plot of the residuals for the NQT model\n",
        "sm.qqplot(residuals_nqt, line='s')\n",
        "plt.title('Q-Q Plot of Residuals (NQT Transformed Model)')\n",
        "plt.show()\n",
        "\n",
        "# Perform the Shapiro-Wilk test on the NQT model residuals\n",
        "shapiro_test_stat_nqt, shapiro_p_value_nqt = shapiro(residuals_nqt)\n",
        "\n",
        "# Print the results of the Shapiro-Wilk test for NQT model residuals\n",
        "print(\"\\nShapiro-Wilk Test Results for Residuals (NQT Model):\")\n",
        "print(f\"  Test Statistic: {shapiro_test_stat_nqt:.4f}\")\n",
        "print(f\"  P-value: {shapiro_p_value_nqt:.4f}\")\n",
        "\n",
        "print(\"\\nVisual inspection of the plots and the Shapiro-Wilk test results are needed to assess normality of residuals.\")"
      ],
      "metadata": {
        "id": "Z17RDB47Jx-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passed the residual normality test"
      ],
      "metadata": {
        "id": "ruL9hrWAKr00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verifying multicolinearity Model 1:\n",
        "if 'df_regression_nqt' not in locals():\n",
        "    print(\"df_regression_nqt not found, creating it from df_transformed_vars...\")\n",
        "    df_regression_nqt = df_transformed_vars[['FOXO1 Qpath_nqt', 'PGR QPath_nqt', 'Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt']].dropna()\n",
        "\n",
        "\n",
        "# Create a DataFrame with the NQT transformed independent variables (X_nqt)\n",
        "X_nqt = df_regression_nqt[['PGR QPath_nqt', 'Serum E2 (pg/ml)_nqt','Serum P4 (ng/ml)_nqt']]\n",
        "\n",
        "# Add a constant term to the independent variables\n",
        "X_nqt = sm.add_constant(X_nqt)\n",
        "\n",
        "# Calculate the VIF for each independent variable\n",
        "vif_data_nqt = pd.DataFrame()\n",
        "vif_data_nqt[\"variable\"] = X_nqt.columns\n",
        "vif_data_nqt[\"VIF\"] = [variance_inflation_factor(X_nqt.values, i)\n",
        "                          for i in range(X_nqt.shape[1])]\n",
        "\n",
        "# Print the VIF values\n",
        "print(\"Variance Inflation Factor (VIF) for NQT transformed independent variables:\")\n",
        "display(vif_data_nqt)\n",
        "\n",
        "print(\"\\nVIF values are generally considered problematic if they are above 5 or 10. Low VIF values indicate that multicollinearity is not a significant issue.\")"
      ],
      "metadata": {
        "id": "JB52QeIiKvxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Verifying multicolinearity Model 2\n",
        "if 'df_regression_nqt' not in locals():\n",
        "    print(\"df_regression_nqt not found, creating it from df_transformed_vars...\")\n",
        "    df_regression_nqt = df_transformed_vars[['FOXO1 Qpath_nqt', 'PGR QPath_nqt', 'Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt']].dropna()\n",
        "\n",
        "\n",
        "# Create a DataFrame with the NQT transformed independent variables (X_nqt) for the second model\n",
        "X_nqt_model2 = df_regression_nqt[['Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt', 'FOXO1 Qpath_nqt']]\n",
        "\n",
        "# Add a constant term to the independent variables\n",
        "X_nqt_model2 = sm.add_constant(X_nqt_model2)\n",
        "\n",
        "# Calculate the VIF for each independent variable\n",
        "vif_data_nqt_model2 = pd.DataFrame()\n",
        "vif_data_nqt_model2[\"variable\"] = X_nqt_model2.columns\n",
        "vif_data_nqt_model2[\"VIF\"] = [variance_inflation_factor(X_nqt_model2.values, i)\n",
        "                              for i in range(X_nqt_model2.shape[1])]\n",
        "\n",
        "# Print the VIF values\n",
        "print(\"Variance Inflation Factor (VIF) for NQT transformed independent variables (PGR QPath_nqt as Dependent):\")\n",
        "display(vif_data_nqt_model2)\n",
        "\n",
        "print(\"\\nVIF values are generally considered problematic if they are above 5 or 10. Low VIF values indicate that multicollinearity is not a significant issue.\")"
      ],
      "metadata": {
        "id": "7sx_woa8RK6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL 1 FOXO1 as dependent variable\n",
        "if 'df_regression_nqt' not in locals():\n",
        "    print(\"df_regression_nqt not found, creating it from df_transformed_vars...\")\n",
        "    df_regression_nqt = df_transformed_vars[['FOXO1 Qpath_nqt', 'PGR QPath_nqt', 'Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt']].dropna()\n",
        "\n",
        "\n",
        "# Define the independent variables (X) and the dependent variable (y) using the NQT transformed data\n",
        "X_nqt = df_regression_nqt[['PGR QPath_nqt', 'Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt']]\n",
        "y_nqt = df_regression_nqt['FOXO1 Qpath_nqt']\n",
        "\n",
        "# Add a constant to the independent variables\n",
        "X_nqt = sm.add_constant(X_nqt)\n",
        "\n",
        "# Fit the multiple linear regression model\n",
        "model_nqt = sm.OLS(y_nqt, X_nqt).fit()\n",
        "\n",
        "# Print the summary of the regression results\n",
        "print(\"Multiple Linear Regression Results (Model 1 - NQT Transformed Variables):\")\n",
        "print(model_nqt.summary())\n",
        "\n",
        "print(\"\\nInterpretation of the results, including coefficients, p-values, R-squared, and assumption checks (linearity, homoscedasticity, normality of residuals, multicollinearity), is needed.\")"
      ],
      "metadata": {
        "id": "VeMDPpfoNY7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: PGR as dependent variable:\n",
        "if 'df_regression_nqt' not in locals():\n",
        "    print(\"df_regression_nqt not found, creating it from df_transformed_vars...\")\n",
        "    df_regression_nqt = df_transformed_vars[['FOXO1 Qpath_nqt', 'PGR QPath_nqt', 'Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt']].dropna()\n",
        "\n",
        "\n",
        "# Define the independent variables (X) and the dependent variable (y) using the NQT transformed data\n",
        "X_nqt = df_regression_nqt[['Serum E2 (pg/ml)_nqt', 'Serum P4 (ng/ml)_nqt', 'FOXO1 Qpath_nqt']]\n",
        "y_nqt = df_regression_nqt['PGR QPath_nqt'] # Dependent variable is PGR QPath_nqt\n",
        "\n",
        "# Add a constant to the independent variables\n",
        "X_nqt = sm.add_constant(X_nqt)\n",
        "\n",
        "# Fit the multiple linear regression model\n",
        "model_pgr_nqt = sm.OLS(y_nqt, X_nqt).fit() # Naming the model specifically for PGR as dependent\n",
        "\n",
        "# Print the summary of the regression results\n",
        "print(\"Multiple Linear Regression Results (Model 2 - PGR QPath as Dependent Variable - NQT Transformed Variables):\")\n",
        "print(model_pgr_nqt.summary())\n",
        "\n",
        "print(\"\\nInterpretation of the results, including coefficients, p-values, R-squared, and assumption checks (linearity, homoscedasticity, normality of residuals, multicollinearity), is needed.\")"
      ],
      "metadata": {
        "id": "RbOwgjWmODKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c046a230"
      },
      "source": [
        "## Explanation of Multiple Linear Regression Results (NQT Transformed Variables)\n",
        "\n",
        "Here is an explanation of the results from the two multiple linear regression models performed using the Normal Quantile Transformed (NQT) variables:\n",
        "\n",
        "### Model 1: Dependent Variable = FOXO1 Qpath\\_nqt\n",
        "\n",
        "(Based on the output of cell `VeMDPpfoNY7V`)\n",
        "\n",
        "*   **Overall Model Fit:**\n",
        "    *   **R-squared = 0.292:** This means that approximately 29.2% of the variance in the Normal Quantile Transformed FOXO1 Qpath can be explained by the NQT transformed independent variables (PGR QPath\\_nqt, Serum E2 (pg/ml)\\_nqt, and Serum P4 (ng/ml)\\_nqt).\n",
        "    *   **Adjusted R-squared = 0.238:** This is a slightly adjusted R-squared value that accounts for the number of predictors in the model.\n",
        "    *   **F-statistic = 5.374, Prob (F-statistic) = 0.00341:** The overall model is statistically significant (p < 0.05). This indicates that at least one of the independent variables significantly predicts the NQT transformed FOXO1 Qpath.\n",
        "\n",
        "*   **Individual Predictors:**\n",
        "    *   **const (Intercept):** The intercept is close to zero (5.51e-05), which is expected when using NQT transformed variables which are centered around zero. It is not statistically significant (p = 1.000).\n",
        "    *   **PGR QPath\\_nqt:** The coefficient is -0.0387. It is **not statistically significant** (p = 0.796). This suggests that, when controlling for the other variables, there is no significant linear relationship between NQT transformed PGR QPath and NQT transformed FOXO1 Qpath.\n",
        "    *   **Serum E2 (pg/ml)\\_nqt:** The coefficient is -0.6543. It is **statistically significant** (p = 0.001). This indicates that, when controlling for the other variables, there is a significant negative linear relationship between NQT transformed Serum E2 and NQT transformed FOXO1 Qpath. For a one-unit increase in NQT transformed Serum E2, NQT transformed FOXO1 Qpath is estimated to decrease by 0.6543 units.\n",
        "    *   **Serum P4 (ng/ml)\\_nqt:** The coefficient is 0.2413. It is **not statistically significant** (p = 0.192). This suggests that, when controlling for the other variables, there is no significant linear relationship between NQT transformed Serum P4 and NQT transformed FOXO1 Qpath.\n",
        "\n",
        "*   **Assumption Checks (based on previous steps):**\n",
        "    *   **Linearity:** Visual inspection of scatter plots (in cell `e8579f3f`) suggested approximate linearity after NQT transformation.\n",
        "    *   **Homoscedasticity:** The Breusch-Pagan test (p-value = 0.1758 in cell `fe981ad6`) suggests that the assumption of homoscedasticity is met (p >= 0.05).\n",
        "    *   **Normality of Residuals:** The Shapiro-Wilk test (p-value = 0.6634 in cell `Z17RDB47Jx-U`) indicates that the assumption of normality of residuals is met (p >= 0.05).\n",
        "    *   **Multicollinearity:** VIF values (all below 2 in cell `JB52QeIiKvxj`) indicate no significant multicollinearity.\n",
        "\n",
        "*   **Summary for Model 1:** The multiple linear regression model with NQT transformed variables is statistically significant and explains about 29.2% of the variance in NQT transformed FOXO1 Qpath. Among the predictors, only NQT transformed Serum E2 is a significant negative predictor. The key regression assumptions (linearity, homoscedasticity, normality of residuals, multicollinearity) appear to be reasonably met after NQT transformation.\n",
        "\n",
        "### Model 2: Dependent Variable = PGR QPath\\_nqt\n",
        "\n",
        "(Based on the output of cell `RbOwgjWmODKX`)\n",
        "\n",
        "*   **Overall Model Fit:**\n",
        "    *   **R-squared = 0.183:** This means that approximately 18.3% of the variance in the Normal Quantile Transformed PGR QPath can be explained by the NQT transformed independent variables (Serum E2 (pg/ml)\\_nqt, Serum P4 (ng/ml)\\_nqt, and FOXO1 Qpath\\_nqt).\n",
        "    *   **Adjusted R-squared = 0.120:** Adjusted R-squared value.\n",
        "    *   **F-statistic = 2.904, Prob (F-statistic) = 0.0468:** The overall model is statistically significant (p < 0.05). This indicates that at least one of the independent variables significantly predicts the NQT transformed PGR QPath.\n",
        "\n",
        "*   **Individual Predictors:**\n",
        "    *   **const (Intercept):** Close to zero (8.835e-05) and not statistically significant (p = 1.000).\n",
        "    *   **Serum E2 (pg/ml)\\_nqt:** The coefficient is 0.3623. It is **not statistically significant** (p = 0.117).\n",
        "    *   **Serum P4 (ng/ml)\\_nqt:** The coefficient is 0.0587. It is **not statistically significant** (p = 0.770).\n",
        "    *   **FOXO1 Qpath\\_nqt:** The coefficient is -0.0447. It is **not statistically significant** (p = 0.796).\n",
        "\n",
        "*   **Assumption Checks (based on previous steps and this model's characteristics):**\n",
        "    *   **Linearity:** Visual inspection of scatter plots of NQT variables (similar to those in cell `e8579f3f` but with PGR as Y) would be needed.\n",
        "    *   **Homoscedasticity:** A Breusch-Pagan test for this specific model would be needed.\n",
        "    *   **Normality of Residuals:** A Shapiro-Wilk test for this specific model's residuals would be needed.\n",
        "    *   **Multicollinearity:** VIF values (all below 2.5 in cell `7sx_woa8RK6e`) indicate no significant multicollinearity among Serum E2\\_nqt, Serum P4\\_nqt, and FOXO1 Qpath\\_nqt.\n",
        "\n",
        "*   **Summary for Model 2:** The multiple linear regression model with NQT transformed variables is statistically significant and explains about 18.3% of the variance in NQT transformed PGR QPath. None of the individual predictors (NQT transformed Serum E2, Serum P4, or FOXO1 Qpath) are statistically significant predictors in this model at the 0.05 level. Multicollinearity is not a significant issue. Further checks for linearity, homoscedasticity, and normality of residuals specifically for this model would be beneficial, although the NQT transformation of the dependent variable is expected to improve residual normality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fa4a0a2"
      },
      "source": [
        "## Statistical Methodology\n",
        "\n",
        "All statistical analyses were performed using Python with the pandas, numpy, matplotlib, statsmodels, scipy, and pingouin libraries. A significance level of $\\alpha = 0.05$ was used for all tests.\n",
        "\n",
        "Descriptive statistics, including mean, standard deviation (SD), median, range, and sample size (n), were calculated for all quantitative variables within each study group (Control, IVF, HRT).\n",
        "\n",
        "The normality of the distribution for each quantitative variable was assessed using D'Agostino's K-squared test. Based on the normality results and assessment of homogeneity of variances (using Levene's test where appropriate), between-group comparisons were performed using one-way Analysis of Variance (ANOVA) for normally distributed data with equal variances, Welch's ANOVA for normally distributed data with unequal variances, and the non-parametric Kruskal-Wallis H-test for non-normally distributed data.\n",
        "\n",
        "The association between categorical variables (Group and HE Dating) was examined using the Chi-squared test of independence. Fisher's exact test was considered if expected cell counts were less than five.\n",
        "\n",
        "To address violations of the normality assumption for certain variables, data transformations were explored, including Log transformation, Box-Cox transformation, and Normal Quantile Transformation (NQT). The effectiveness of these transformations was evaluated using D'Agostino's K-squared test on the transformed data.\n",
        "\n",
        "Multiple linear regression analysis was performed to investigate the relationships between selected variables. Two primary models were examined:\n",
        "1.  With FOXO1 Qpath as the dependent variable and Serum E2 (pg/ml), Serum P4 (ng/ml), and PGR QPath as independent variables.\n",
        "2.  With PGR QPath as the dependent variable and Serum E2 (pg/ml), Serum P4 (ng/ml), and FOXO1 Qpath as independent variables.\n",
        "\n",
        "Prior to regression analysis, key assumptions were assessed:\n",
        "*   Linearity was visually inspected using scatter plots between the dependent and independent variables.\n",
        "*   Homoscedasticity (constancy of residual variance) was assessed visually with scatter plots of residuals versus predicted values and formally using the Breusch-Pagan test.\n",
        "*   The normality of residuals was evaluated using histograms, Q-Q plots, and the Shapiro-Wilk test.\n",
        "*   Multicollinearity among independent variables was assessed using the Variance Inflation Factor (VIF).\n",
        "\n",
        "Data transformations were applied to the dependent variable when the normality of residuals assumption was violated, and regression analysis was re-run with the transformed variable.\n",
        "\n",
        "Regression model results were interpreted based on the estimated coefficients, standard errors, p-values, and the overall model fit (R-squared and F-statistic)."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9GjDBiI6TS4m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}